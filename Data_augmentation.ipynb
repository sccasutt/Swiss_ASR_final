{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b47d0a-3890-4b50-b5fb-e987bf6b9dc3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "47b47d0a-3890-4b50-b5fb-e987bf6b9dc3",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install torchaudio\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0330c4bd-60dc-44cc-b031-6d377ec876d6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "0330c4bd-60dc-44cc-b031-6d377ec876d6",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "import requests\n",
    "import scipy.signal as sg\n",
    "import pydub\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9547880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#with zipfile.ZipFile(\"audio.zip\",\"r\") as zip_ref:\n",
    "#    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 13 #where to split file path to insert new folder toy_data:7 full_data=13\n",
    "df = pd.read_csv(\"train_data_full.csv\")\n",
    "csv_name = \"train_data_\"\n",
    "df.drop(\"Unnamed: 0\",axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e030d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Noise Augmentation Test #2: More Noise\n",
    "#Noise amplification first run: noise = np.asarray(0.01*np.random.randn(len(audio)))\n",
    "#Noise augmentation second run: noise = np.asarray(0.1*np.random.randn(len(audio)))\n",
    "#remember to run zip with same settings (folder = augment_0.1)\n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/full_random_noise_01/\"\n",
    "noise_factor = 0.1\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "    audio = librosa.resample(audio,sr, target_sr=16000)\n",
    "    noise = np.asarray(noise_factor*np.random.randn(len(audio)))\n",
    "    audio_noise = np.asarray(audio + noise)\n",
    "    new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "    sf.write(new_filename,audio_noise,16000)\n",
    "    new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]  \n",
    "    \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03394f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"full_random_noise_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random Gaussian Noise generator\n",
    "#generate random length noise \n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/random_noise_0.1\"\n",
    "noise_factor = 0.1\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "    audio = librosa.resample(audio,sr, target_sr=16000)\n",
    "    \n",
    "    noise_strength = noise_factor\n",
    "    \n",
    "    noise = np.random.uniform(0.0,noise_strength,len(audio))\n",
    "\n",
    "    random_number_chunks = 10 #np.random.randint(1,10)\n",
    "\n",
    "    chunk = int(len(audio)/random_number_chunks)\n",
    "    \n",
    "    mask=[]\n",
    "    \n",
    "    for j in range(1,random_number_chunks+1): \n",
    "\n",
    "        masking_range = noise[(j*chunk-chunk):(j*chunk)]\n",
    "        start = np.random.randint(0,len(masking_range))\n",
    "        stop = start + int(len(masking_range))\n",
    "        masking_range[start:stop] = 0\n",
    "    \n",
    "    audio_noise = np.asarray(audio + noise)\n",
    "    \n",
    "    new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "    \n",
    "    sf.write(new_filename,audio_noise,16000)\n",
    "\n",
    "    new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]  \n",
    "    \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbab1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#every 10 ms there is a chance that audio will be masked --> Chopy audio\n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/random_augment\"\n",
    "mask_ms = 10\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    \n",
    "    masked_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "    masked_audio = librosa.resample(masked_audio,sr, target_sr=16000)\n",
    "    index_length = int(sr/mask_ms)\n",
    "    \n",
    "    for j in range(0,len(masked_audio),index_length):\n",
    "        random_chance = np.random.randint(1,10)\n",
    "        if random_chance > 7:\n",
    "            masked_audio[j:j+index_length] = 0\n",
    "    \n",
    "    new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "    \n",
    "    sf.write(new_filename,masked_audio,16000)\n",
    "\n",
    "    new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]  \n",
    "    \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed change slow\n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/slow_10pct\"\n",
    "speed_change = 1.1 #change < 1 is faster change > 1 is slower\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    \n",
    "    masked_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "    masked_audio = librosa.resample(masked_audio,sr, target_sr=16000*speed_change)\n",
    "    \n",
    "    new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "    \n",
    "    sf.write(new_filename,masked_audio,16000)\n",
    "\n",
    "    new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]  \n",
    "    \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed change fast\n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/fast_10pct\"\n",
    "speed_change = 0.9 #change < 1 is faster change > 1 is slower\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    \n",
    "    masked_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "    masked_audio = librosa.resample(masked_audio,sr, target_sr=16000*speed_change)\n",
    "    \n",
    "    new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "    \n",
    "    sf.write(new_filename,masked_audio,16000)\n",
    "\n",
    "    new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]  \n",
    "    \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random high pass filter\n",
    "\n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/random_high_pass\"\n",
    "\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    \n",
    "        audio,sr = librosa.load(df[\"audio_path\"][i])\n",
    "        \n",
    "        audio = librosa.resample(audio,sr, target_sr=16000)\n",
    "        \n",
    "        high_cutoff = random.randint(200,1000)\n",
    "\n",
    "        b, a = sg.butter(4, high_cutoff / (sr / 2.), 'high')\n",
    "        \n",
    "        cutoff_audio = sg.filtfilt(b, a, audio)\n",
    "        \n",
    "        new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "\n",
    "        sf.write(new_filename,cutoff_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]\n",
    "        \n",
    "        \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random low pass filter\n",
    "\n",
    "new_df = df.copy()\n",
    "run_name = \"/random_low_pass\"\n",
    "\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    \n",
    "        audio,sr = librosa.load(df[\"audio_path\"][i])\n",
    "        \n",
    "        audio = librosa.resample(audio,sr, target_sr=16000)\n",
    "        \n",
    "        high_cutoff = random.randint(1000,1500)\n",
    "\n",
    "        b, a = sg.butter(4, high_cutoff / (sr / 2.), 'high')\n",
    "        \n",
    "        cutoff_audio = sg.filtfilt(b, a, audio)\n",
    "        \n",
    "        new_filename = df[\"audio_path\"][i][:split]+run_name+df[\"audio_path\"][i][split:]\n",
    "\n",
    "        sf.write(new_filename,cutoff_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:split]+run_name+new_df[\"audio_path\"][i][split:]\n",
    "        \n",
    "        \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(csv_name+run_name[1:]+\".csv\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmenting testset\n",
    "#number of augmentations availible: 7\n",
    "### This whole block could be solved more elegantly by defining the funktionality above as seperate functions\n",
    "### TODO: implement seperate augemntations as funkitons\n",
    "\n",
    "df.drop(\"Unnamed: 0\",axis=1, inplace=True)\n",
    "new_df = df.copy()\n",
    "run_name = \"full_test_random_augment/\"\n",
    "speed_change_slow = 1.11\n",
    "speed_change_fast = 0.913\n",
    "noise_factor = 0.012\n",
    "mask_ms=27\n",
    "\n",
    "for i in range(len(new_df)):\n",
    "    \n",
    "    pick = random.randint(1,7)\n",
    "    \n",
    "    if pick == 1: #simple random gaussian noise\n",
    "        df.loc[i,\"augmentation\"] = \"random noise\"\n",
    "        \n",
    "        noise_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "\n",
    "        noise_audio = librosa.resample(noise_audio,sr, target_sr=16000)\n",
    "       \n",
    "        noise = np.asarray(noise_factor*np.random.randn(len(noise_audio)))\n",
    "        \n",
    "        audio_noise = np.asarray(noise_audio + noise)\n",
    "        \n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "        \n",
    "        sf.write(new_filename,audio_noise,16000)\n",
    "        \n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:]\n",
    "        \n",
    "    elif pick == 2: #noise bursts\n",
    "         \n",
    "        df.loc[i,\"augmentation\"] = \"noise burst\"\n",
    "        \n",
    "        random_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "        \n",
    "        random_audio = librosa.resample(random_audio,sr, target_sr=16000)\n",
    "\n",
    "\n",
    "        random_noise = np.random.uniform(0.0,noise_factor*10,len(random_audio))\n",
    "\n",
    "        random_number_chunks = 10 #np.random.randint(1,10)\n",
    "\n",
    "        chunk = int(len(random_audio)/random_number_chunks)\n",
    "\n",
    "        for j in range(1,random_number_chunks+1): \n",
    "\n",
    "            masking_range = random_noise[(j*chunk-chunk):(j*chunk)]\n",
    "            \n",
    "            start = np.random.randint(0,len(masking_range))\n",
    "            stop = start + int(len(masking_range))\n",
    "            \n",
    "            masking_range[start:stop] = 0\n",
    "                        \n",
    "        audio_noise = np.asarray(random_audio + random_noise)\n",
    "\n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "\n",
    "        sf.write(new_filename,audio_noise,16000)\n",
    "        \n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:]\n",
    "\n",
    "\n",
    "    if pick == 3: #mask out parts of audio\n",
    "        \n",
    "        df.loc[i,\"augmentation\"] = \"masked audio\"\n",
    "        \n",
    "        masked_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "        masked_audio = librosa.resample(masked_audio,sr, target_sr=16000)\n",
    "        index_length = int(sr/mask_ms)\n",
    "\n",
    "        for j in range(0,len(masked_audio),index_length):\n",
    "            random_chance = np.random.randint(1,10)\n",
    "            if random_chance > 7:\n",
    "                masked_audio[j:j+index_length] = 0\n",
    "\n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "\n",
    "        sf.write(new_filename,masked_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:] \n",
    "    \n",
    "    if pick == 4: #slow down audio\n",
    "        df.loc[i,\"augmentation\"] = \"slow\"\n",
    "        slow_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "        slow_audio = librosa.resample(slow_audio,sr, target_sr=16000*speed_change_slow)\n",
    "\n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "\n",
    "        sf.write(new_filename,slow_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:]\n",
    "        \n",
    "    if pick == 5: #speed up audio\n",
    "        df.loc[i,\"augmentation\"] = \"fast\"\n",
    "        fast_audio, sr = librosa.load(df[\"audio_path\"][i])\n",
    "        fast_audio = librosa.resample(fast_audio,sr, target_sr=16000*speed_change_fast)\n",
    "\n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "\n",
    "        sf.write(new_filename,fast_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:] \n",
    "        \n",
    "    if pick == 6: #random highpass\n",
    "        df.loc[i,\"augmentation\"] = \"high_pass\"\n",
    "        high_cutoff_audio,sr = librosa.load(df[\"audio_path\"][i])\n",
    "        \n",
    "        high_cutoff_audio = librosa.resample(high_cutoff_audio,sr, target_sr=16000)\n",
    "        \n",
    "        high_cutoff = random.randint(200,1000)\n",
    "\n",
    "        b, a = sg.butter(4, high_cutoff / (sr / 2.), 'high')\n",
    "        \n",
    "        cutoff_audio = sg.filtfilt(b, a, high_cutoff_audio)\n",
    "        \n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "\n",
    "        sf.write(new_filename,cutoff_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:]\n",
    "        \n",
    "    if pick == 7: #random low pass\n",
    "        df.loc[i,\"augmentation\"] = \"low pass\"\n",
    "        low_cutoff_audio,sr = librosa.load(df[\"audio_path\"][i])\n",
    "        \n",
    "        low_cutoff_audio = librosa.resample(low_cutoff_audio,sr, target_sr=16000)\n",
    "        \n",
    "        low_cutoff = random.randint(1000,1500)\n",
    "\n",
    "        b, a = sg.butter(4, low_cutoff / (sr / 2.), 'low')\n",
    "        \n",
    "        low_cutoff_audio = sg.filtfilt(b, a, low_cutoff_audio)\n",
    "        \n",
    "        new_filename = df[\"audio_path\"][i][:13]+run_name+df[\"audio_path\"][i][13:]\n",
    "\n",
    "        sf.write(new_filename,low_cutoff_audio,16000)\n",
    "\n",
    "        new_df.loc[i,\"audio_path\"] = new_df[\"audio_path\"][i][:13]+run_name+new_df[\"audio_path\"][i][13:]\n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "       \n",
    "df = pd.concat([df,new_df],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(\"full_data_augment_random.csv\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
